---
title: "Trump Vote Request"
output: 
   html_document:
    toc: yes
    toc_depth: 3
    css: style.css
params:
  date: !r Sys.Date()    
---

```{r, warning=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(data.table)
library(readr)
library(stringi)
library(RtextminerPkg)
library(RplotterPkg)
library(RtsaPkg)
library(tm)
library(sentimentr)
library(here)

current_dir <- here()
```

```{r,setup, include=FALSE, eval=TRUE}
options(knitr.table.format = "html", width = 160)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 8)
```

<div>Author: Rick Dean</div>
<div>Article date: `r params$date`</div>

<div class="abstract">
  <p class="abstract">Abstract</p>
  The following R script is an analysis of the Trump phone call to Georgia's Secretary of State Brad Raffensperger on the presidential election results in that state (January 4, 2021).
</div>  

## Study Outline

### Read the phone transcript data
```{r}
data_file_path <- file.path(current_dir, "trump_vote_request.txt")
linesInFile <- base::readLines(data_file_path)
```
### Show file statistics
```{r}
fileSize <- format(object.size(linesInFile), units = "Kb")
fileNoLines <- length(linesInFile)
fileWords <- sum(stringi::stri_count_words(linesInFile))

cat(" File size: ", fileSize, " Lines in file: ", fileNoLines, " Words in file: ", fileWords)
```

### Get the sentence collection
```{r}
sentences_v <- unlist(sentimentr::get_sentences(linesInFile))
sentences_dt <-  data.table(
  sentence_no = 1:length(sentences_v),
  sentence_text = sentences_v
)
```

### Remove blanks from the sentence collection
```{r}
sentences_dt <- sentences_dt[nchar(sentence_text) > 1]
```

### Tokenize the lines to words
Note: We are defining stopwords from the [tm package](https://cran.r-project.org/web/packages/tm/index.html). The  word "trump" occurs in the text 64 times and has several meanings.  Because "trump" is a personal name we will include it in the vector of stopwords.

```{r}
words_dt <- RtextminerPkg::tokenize_text(
  x = sentences_dt,
  input_col = "sentence_text",
  stopwords = append(tm::stopwords("en"), "trump"),
  strip_numeric = T,
  strip_punct = T,
  strip_non_alphanum = T
)
head(words_dt$tokens_dt,n = 10)
```

### Plot the 20 most common words
```{r}
RplotterPkg::create_bar_plot(
  df = words_dt$tokens_count[1:20],
  aes_x = "word",
  aes_y = "N",
  title = "Most Common Words in Trump's Phone Call",
  subtitle = "Call to Georgia's Secretary of State",
  x_title = "Word",
  y_title = "Number of Occurances",
  rot_y_tic_label = T,
  bar_fill = "blue",
  bar_color = "gold",
  bar_alpha = 0.7,
  do_coord_flip = T,
  order_bars = "asc",
  bar_labels = T
)
```

### Relationship of the word "know"
The word "know" has the highest frequency in the conversation.  What is the relationship of this word with other words.  To accomplish this we will perform an [N-gram](https://en.wikipedia.org/wiki/N-gram) analysis.

1. Perform 2-gram tokenization:
Note: By default `n-gram` = 2 for `RtextminerPkg::tokenize_text()`
```{r}
bigrams_dt <- RtextminerPkg::tokenize_text(
  x = sentences_dt,
  input_col = "sentence_text",
  type = "ngram"
)
```
2. Paste the 2 words together in a separate column to form the `bigram` variable in the data.table`bigrams_dt$tokens_count`:
```{r}
bigrams_dt$tokens_count[, bigram := paste(token_1, token_2)]
```

3. Plot the 22 top 2-gram's:
```{r}
RplotterPkg::create_bar_plot(
  df = bigrams_dt$tokens_count[1:22],
  aes_x = "bigram",
  aes_y = "N",
  title = "Most Common 2-gram's in Trump's Phone Call",
  subtitle = "Call to Georgia's Secretary of State",
  x_title = "2-gram",
  y_title = "Number of Occurances",
  rot_y_tic_label = T,
  bar_fill = "blue",
  bar_color = "gold",
  bar_alpha = 0.7,
  do_coord_flip = T,
  order_bars = "asc",
  bar_labels = T
)
```

The phrase "you know" appears to be the most frequent 2-gram. The phrase "we won" has some interesting context.

```{r}
we_won_dt <- sentences_dt[data.table::like(sentences_dt$sentence_text, "we won",ignore.case = T)]
```
```{r}
we_won_table <- RplotterPkg::create_table(
  x = we_won_dt,
  caption = "'we won' phrases",
  fixed_thead = T,
  scroll_height = "400px"
)
we_won_table
```



### Measure the sentiment of each sentence
The R package being used here for sentiment measurement is [sentimentr::sentiment()](https://github.com/trinker/sentimentr) where the author states "is designed to quickly calculate text polarity sentiment at the sentence level and optionally aggregate by rows or grouping variable(s)."  He goes on to say that "sentimentr attempts to take into account valence shifters (i.e., negators, amplifiers (intensifiers), de-amplifiers (downtoners), and adversative conjunctions) while maintaining speed."


```{r}
sentence_sentiment_dt <- sentimentr::sentiment(sentences_dt$sentence_text)
sentence_sentiment_dt[,sentence_id := sentences_dt$sentence_no]
head(sentence_sentiment_dt, n = 10)
```
### Plot the sentiment measures
```{r,fig.width=13, fig.height=8}
RplotterPkg::create_scatter_plot(
  df = sentence_sentiment_dt,
  aes_x = "sentence_id",
  aes_y = "sentiment",
  connect = T,
  x_limits = c(0,900),
  x_major_breaks = seq(0,900,100),
  y_limits = c(-1,1.25),
  y_major_breaks = seq(-1,1.25,0.25),
  show_minor_grids = F,
  title = "Sentiment analysis of Trump phone call to Georgia's Secretary of State",
  subtitle = "743 sentences; 4674 words"
)
```


```{r}
postive_sentences_dt <- data.table(
  sentence_no = c(453,875,549,725),
  sentence_text = c("Go ahead, please.", 
                    "And the truth, the real truth is I won by 400,000 votes, at least.",
                    "It was much more criminal than that.",
                    "They’re really wrong, and they’re really wrong, Brad."),
  sentiment = c(1.039, 1.026,-0.737,-0.854)
)
postive_table <- RplotterPkg::create_table(
  x = postive_sentences_dt,
  caption = "Significant Sentences"
)
postive_table
```

```{r,fig.width=13, fig.height=8}
RtsaPkg::graph_ma(
  df = sentence_sentiment_dt,
  time_col = "sentence_id",
  value_col = "sentiment",
  window_n = 10,
  #ma_type = "wma",
  show_observe = F,
  title = "Sentiment analysis of Trump phone call to Georgia's Secretary of State",
  subtitle = "Simple moving average sentiment of 743 sentences",
  x_limits = c(0,900),
  x_major_breaks = seq(0,900,100),
  show_pts = F,
  display_plot = F
)
```

There appears to be some negative sentiment spiking near the middle of the conversation. 
